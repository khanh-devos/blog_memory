---
category: ai
loadingMathjax: true
---

A vector is a mathematical object that represents a quantity with both magnitude and direction

1. **Magnitude $\Vert v \Vert$** : a length or size of vector, given a vector $\vec{v}$ = [$v_{1}$, $v_{2}$,... , $v_{n}$], we have:

    $\Vert v \Vert$ = $\sqrt {v_{1}^{2} + v_{2}^{2} ... + v_{n}^{2}}$

2. **Direction** : The relative orientation of a vector in space.

3. **Dot Product (Inner Product = IP)** : an operation that combines two vectors to yield a scalar.
    - For 2 vectors $\vec{u}$ = [$u_{1}$, $u_{2}$,... , $u_{n}$] and $\vec{v}$ = [$v_{1}$, $v_{2}$,... , $v_{n}$]:

    $$\vec{u} \cdot \vec{v} = \sum_{i=1}^{n} {u_{i} \cdot v_{i}} = IP$$
    
    - The dot product is used to measure the angle between vectors, if *dot product = 0*, then 2 vectors are *perpendicular* and their angle is $90^{o}$ or $270^{o}$.
    - In numpy, np.dot($\vec{u}$, $\vec{v}$)
    - **Magnitude $\Vert v \Vert$** = $\sqrt{IP \ of \ itself}$ = $\sqrt{\vec{v} \cdot \vec{v}}$.

    - **Extention 1** : If we consider two vectors as 1-D matrices, the inner product looks like matrix multiplication. However, when using np.dot() with matrices, the result is another matrix rather than a scalar.

    - **Extension 2** : IP can be used to calculate the angle $\alpha$ between 2 vectors:
    
    $$ cos(\alpha) = \frac{IP}{\Vert u \Vert \cdot \Vert v \Vert} $$ 

    - **Extention 3** : Length $Pro^{u}_{v}$ of projection(Hình chiếu) of vector $\vec{u}$ on vector $\vec{v}$:

    $$ Pro^{u}_{v} = cos(\alpha) \cdot \Vert u \Vert = \frac{IP}{\Vert v \Vert} $$ 

4. **Softmax**: a function used to transform a vector into another vector, which has the sum of all elements is 1, making it like a probability distribution. The formula for softmax for a vector $\vec{z}$ = [$z_{1}$, $z_{2}$,... , $z_{n}$]:

    $$softmax(z_{i}) = \frac{e^{z_{i}}}{\sum_{j=1}^{n} {e^{z_{j}}}}$$

    - For example : z = [2, 1, 0.1]<br>
    Calculate $e^{z_{i}}$ :  $e^{2}$ = 7.39, $e^{1}$ = 2.72, $e^{0.1}$ = 1.11<br>
    
    Sum: 7.39 + 2.72 + 1.11 = 11.22<br>
    
    softmax($z_{1}$) = 7.39/11.22 = 0.66<br>
    softmax($z_{2}$) = 7.39/11.22 = 0.24<br>
    softmax($z_{3}$) = 7.39/11.22 = 0.10<br>
    
    After softmax(z) = [0.66, 0.24, 0.10], with the sum = 1


    

    

